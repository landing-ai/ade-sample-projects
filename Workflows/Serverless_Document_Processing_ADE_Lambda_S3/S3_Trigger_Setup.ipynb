{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S3 Trigger Setup - Automatic Document Processing with ADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---\n",
    "# LandingAI Applied AI Content Notebook Template\n",
    "# ---\n",
    "# Title: S3 Trigger Setup - Automatic Document Processing with ADE\n",
    "# Author: Ava Xia\n",
    "# Description: Streamlined notebook for testing and using the deployed Lambda function\n",
    "# Target Audience: [Developers, Partners, Customers]\n",
    "# Content Type: [Tutorial, How-To]\n",
    "# Publish Date: 2025-09-23\n",
    "# ADE Version: v0.1.5\n",
    "# Change Log:\n",
    "#    - v1.0: Initial draft\n",
    "#    - v1.1: Modularized with utility functions\n",
    "# ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook configures automatic processing when documents are uploaded to S3.\n",
    "\n",
    "**‚ö†Ô∏è IMPORTANT:** Make sure your AWS session is in the same region as your Lambda function and S3 bucket (in our case `us-east-2`). \n",
    "\n",
    "If using AWS SSO, login with:\n",
    "```bash\n",
    "aws configure sso\n",
    "aws sso login --profile your-profile-name\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How S3 Triggers Work\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  Upload  ‚îÇ ---> ‚îÇ    S3    ‚îÇ ---> ‚îÇ  Trigger ‚îÇ ---> ‚îÇ  Lambda  ‚îÇ\n",
    "‚îÇ   PDF    ‚îÇ      ‚îÇ  Bucket  ‚îÇ      ‚îÇ  Event   ‚îÇ      ‚îÇ Process  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                                           ‚îÇ                 ‚îÇ\n",
    "                                           ‚Üì                 ‚Üì\n",
    "                                    Automatic         Save Results\n",
    "```\n",
    "\n",
    "When you upload a PDF to the configured S3 folder:\n",
    "1. S3 generates an event\n",
    "2. Event triggers Lambda function\n",
    "3. Lambda processes the document\n",
    "4. Results saved to `ade-results/` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üîß Initializing AWS environment...\n",
      "============================================================\n",
      "‚úÖ AWS Environment configured\n",
      "   Profile: workload-dev-2\n",
      "   Region: us-east-2\n",
      "   Account: 9700XXXX1993\n",
      "\n",
      "‚úÖ Environment ready!\n",
      "   Lambda: ade-lambda-s3\n",
      "   Bucket: cf-mle-testing\n",
      "   Region: us-east-2\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Import consolidated utilities and configuration\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from IPython.display import display, JSON\n",
    "\n",
    "# Import consolidated modules\n",
    "from config import get_settings\n",
    "from utils import (\n",
    "    setup_aws_environment,\n",
    "    list_s3_files,\n",
    "    check_lambda_environment,\n",
    "    setup_s3_trigger,\n",
    "    get_lambda_invocation_stats,\n",
    "    get_error_logs\n",
    ")\n",
    "\n",
    "# Initialize environment using config.py and .env\n",
    "print(\"=\"*60)\n",
    "print(\"üîß Initializing AWS environment...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load configuration (automatically reads from .env)\n",
    "config, clients, AWS_ACCOUNT_ID, aws_session = setup_aws_environment()\n",
    "\n",
    "# Check if credentials are valid\n",
    "if AWS_ACCOUNT_ID in ['EXPIRED', 'ERROR']:\n",
    "    print(\"\\n‚ö†Ô∏è  Please refresh your AWS credentials:\")\n",
    "    print(\"   aws sso login --profile your-profile-name\")\n",
    "    print(\"   export AWS_DEFAULT_REGION=us-east-2\")\n",
    "else:\n",
    "    # Extract configuration values\n",
    "    BUCKET_NAME = config['bucket_name']\n",
    "    FUNCTION_NAME = config['function_name']\n",
    "    ECR_REPO = config['ecr_repo']\n",
    "    AWS_REGION = config['aws_region']\n",
    "    \n",
    "    print(\"\\n‚úÖ Environment ready!\")\n",
    "    print(f\"   Lambda: {FUNCTION_NAME}\")\n",
    "    print(f\"   Bucket: {BUCKET_NAME}\")\n",
    "    print(f\"   Region: {AWS_REGION}\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure S3 Trigger\n",
    "\n",
    "Set up automatic processing for a specific folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Setting up S3 trigger for: invoices/\n",
      "\n",
      "‚ÑπÔ∏è  S3 permission already exists\n",
      "‚úÖ S3 trigger configured!\n",
      "   üì§ Upload PDFs to: s3://cf-mle-testing/invoices/\n",
      "   ‚ö° They will auto-process with Lambda\n",
      "\n",
      "‚úÖ S3 trigger is active!\n",
      "   Any PDF uploaded to s3://cf-mle-testing/invoices/\n",
      "   will be automatically processed\n"
     ]
    }
   ],
   "source": [
    "# Configure S3 trigger for invoices folder\n",
    "trigger_folder = \"invoices/\"\n",
    "\n",
    "print(f\"üéØ Setting up S3 trigger for: {trigger_folder}\")\n",
    "print()\n",
    "\n",
    "success = setup_s3_trigger(\n",
    "    clients['s3'],\n",
    "    clients['lambda'],\n",
    "    BUCKET_NAME,\n",
    "    FUNCTION_NAME,\n",
    "    folder=trigger_folder\n",
    ")\n",
    "\n",
    "if success:\n",
    "    print(\"\\n‚úÖ S3 trigger is active!\")\n",
    "    print(f\"   Any PDF uploaded to s3://{BUCKET_NAME}/{trigger_folder}\")\n",
    "    print(\"   will be automatically processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test the Trigger\n",
    "\n",
    "Upload a test file to verify the trigger works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì§ Uploading test file...\n",
      "   From: input_folder/invoice_1.pdf\n",
      "   To: s3://cf-mle-testing/invoices/test_trigger_20250925_153109.pdf\n",
      "\n",
      "‚úÖ File uploaded successfully!\n",
      "‚è≥ Waiting for Lambda to process...\n",
      "üìÇ Files in s3://cf-mle-testing/ade-results/\n",
      "Found 5 files\n",
      "\n",
      "‚úÖ Processing complete!\n",
      "   Recent results:\n",
      "   ‚Ä¢ ade-results/batch_extracted_20250924_195832.json\n",
      "   ‚Ä¢ ade-results/batch_extracted_20250925_013951.json\n",
      "   ‚Ä¢ ade-results/batch_extracted_20250925_014051.json\n"
     ]
    }
   ],
   "source": [
    "# Test file upload\n",
    "import time  # Add missing import\n",
    "\n",
    "test_file_path = \"input_folder/invoice_1.pdf\"  # Local file\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "s3_key = f\"{trigger_folder}test_trigger_{timestamp}.pdf\"\n",
    "\n",
    "print(\"üì§ Uploading test file...\")\n",
    "print(f\"   From: {test_file_path}\")\n",
    "print(f\"   To: s3://{BUCKET_NAME}/{s3_key}\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    # Upload the file\n",
    "    clients['s3'].upload_file(test_file_path, BUCKET_NAME, s3_key)\n",
    "    print(\"‚úÖ File uploaded successfully!\")\n",
    "    print(\"‚è≥ Waiting for Lambda to process...\")\n",
    "    \n",
    "    # Wait for processing\n",
    "    time.sleep(10)\n",
    "    \n",
    "    # Check for results\n",
    "    results = list_s3_files(\n",
    "        clients['s3'],\n",
    "        BUCKET_NAME,\n",
    "        \"ade-results/\",\n",
    "        max_files=5\n",
    "    )\n",
    "    \n",
    "    if results:\n",
    "        print(\"\\n‚úÖ Processing complete!\")\n",
    "        print(\"   Recent results:\")\n",
    "        for r in results[:3]:\n",
    "            print(f\"   ‚Ä¢ {r['File']}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Still processing or no results yet\")\n",
    "        print(\"   Check CloudWatch logs for details\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Test file not found: {test_file_path}\")\n",
    "    print(\"   Please update the path to a valid PDF file\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Upload failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Monitor Lambda Invocations\n",
    "\n",
    "Check Lambda statistics to see trigger activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Lambda Invocation Statistics (last 1 hours)\n",
      "==================================================\n",
      "   Total Invocations: 1\n",
      "\n",
      "üìä Recent Activity (last hour):\n",
      "   Invocations: 1\n",
      "   Success rate: 100%\n"
     ]
    }
   ],
   "source": [
    "# Get Lambda invocation stats\n",
    "stats = get_lambda_invocation_stats(\n",
    "    clients['logs'],\n",
    "    FUNCTION_NAME,\n",
    "    hours_back=1  # Last hour\n",
    ")\n",
    "\n",
    "if stats.get('total_invocations', 0) > 0:\n",
    "    print(f\"\\nüìä Recent Activity (last hour):\")\n",
    "    print(f\"   Invocations: {stats['total_invocations']}\")\n",
    "    print(f\"   Success rate: {stats.get('success_rate', 0):.0f}%\")\n",
    "else:\n",
    "    print(\"\\n‚ÑπÔ∏è No recent invocations\")\n",
    "    print(\"   Upload a file to trigger processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Check for Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error Logs (last 1 hours)\n",
      "==================================================\n",
      "‚úÖ No errors found\n",
      "‚úÖ No errors in the last hour\n"
     ]
    }
   ],
   "source": [
    "# Check for recent errors\n",
    "errors = get_error_logs(\n",
    "    clients['logs'],\n",
    "    FUNCTION_NAME,\n",
    "    hours_back=1\n",
    ")\n",
    "\n",
    "if not errors:\n",
    "    print(\"‚úÖ No errors in the last hour\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Found {len(errors)} errors\")\n",
    "    print(\"   Check CloudWatch logs for details\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Remove S3 Trigger\n",
    "\n",
    "If needed, remove the S3 trigger configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è To remove triggers, uncomment the code above\n"
     ]
    }
   ],
   "source": [
    "# Remove S3 trigger (uncomment to run)\n",
    "\"\"\"\n",
    "print(\"üóëÔ∏è Removing S3 trigger...\")\n",
    "\n",
    "try:\n",
    "    # Clear bucket notifications\n",
    "    clients['s3'].put_bucket_notification_configuration(\n",
    "        Bucket=BUCKET_NAME,\n",
    "        NotificationConfiguration={}\n",
    "    )\n",
    "    print(\"‚úÖ S3 trigger removed\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error removing trigger: {e}\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"‚ÑπÔ∏è To remove triggers, uncomment the code above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Best Practices\n",
    "\n",
    "### Folder Organization\n",
    "```\n",
    "s3://bucket/\n",
    "‚îú‚îÄ‚îÄ invoices/        # Auto-process with invoice schema\n",
    "‚îú‚îÄ‚îÄ receipts/        # Auto-process with receipt schema\n",
    "‚îú‚îÄ‚îÄ documents/       # Auto-process with parsing mode\n",
    "‚îú‚îÄ‚îÄ ade-results/     # Processing results\n",
    "‚îî‚îÄ‚îÄ archive/         # Processed files (optional)\n",
    "```\n",
    "\n",
    "### Tips\n",
    "1. **Use specific folders** for different document types\n",
    "2. **Monitor CloudWatch** for processing logs\n",
    "3. **Set up SNS** for processing notifications\n",
    "4. **Archive processed files** to avoid reprocessing\n",
    "5. **Use versioning** on S3 bucket for safety"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
